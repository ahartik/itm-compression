\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{url}

\newcommand{\code}{\texttt}

\title{Project in Information-Theoretic Modeling Final Report}
\author{Aleksi Hartikainen \and Mikko Sysikaski}

\begin{document}
\maketitle

%\abstract{}

%\newpage
%\tableofcontents
%\newpage

\section*{Problem 1}

The first task was to compress a sequence of bits using side data that was also available during decompression.

The file to be compressed had $100\,000$ binary digits, so trivially packing the bits yields a file of size $12\,500$ bytes.
For comparison, we also tried packing the data this way as the decompression code becomes much smaller and simpler.
This gave a total size of around 13.5~KiB uncompressed, and 12.5~KiB after compressing with gzip.

The task was to use arithmetic coding with probabilities from the given model.
Instead of using probabilities from model definition, we computed actual conditional frequencies from the data.
That is, for every tuple $(x_1,x_2,x_3,x_4)$ we counted how many times $x_0$ is 0 and 1, and this gave us the conditional probability of $x_0$ with respect to the other variables.
The calculated probabilities are shown in Figure~\ref{ex1_probs}.
We created a custom implementation of arithmetic coding that used the conditional probabilities of Figure~\ref{ex1_probs} to encode each bit.

Using arithmetic coding and the conditional probabilities, we got the data compressed in 8100~bytes.
Together with the decompression program, this gave a total file size of 9832~bytes.

To evaluate the correctness of our arithmetic coding implementation, we calculated also the theoretical bound for data size using entropy coding.
According to probabilities in Figure~\ref{ex1_probs}, the total entropy of the input file is 64790.4~bits, which is 8098.8~bytes, so the result generated by our implementation is within 1 byte of the theoretical optimum.


\begin{figure}
\label{ex1_probs}

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$x_1$ & $x_2$ & $x_3$ & $x_4$ & $P(x_0 = 0)$ & $P(x_0 = 1) $ \\ \hline
   0 & 0 & 0 & 0 & 0.74244 & 0.25756 \\ \hline
   1 & 0 & 0 & 0 & 0.180631 & 0.819369 \\ \hline
   0 & 1 & 0 & 0 & 0.122035 & 0.877965 \\ \hline
   1 & 1 & 0 & 0 & 0.595336 & 0.404664 \\ \hline
   0 & 0 & 1 & 0 & 0.507643 & 0.492357 \\ \hline
   1 & 0 & 1 & 0 & 0.072675 & 0.927325 \\ \hline
   0 & 1 & 1 & 0 & 0.0461351 & 0.953865 \\ \hline
   1 & 1 & 1 & 0 & 0.359641 & 0.640359 \\ \hline
   0 & 0 & 0 & 1 & 0.888336 & 0.111664 \\ \hline
   1 & 0 & 0 & 1 & 0.37004 & 0.62996 \\ \hline
   0 & 1 & 0 & 1 & 0.277587 & 0.722413 \\ \hline
   1 & 1 & 0 & 1 & 0.78809 & 0.21191 \\ \hline
   0 & 0 & 1 & 1 & 0.733648 & 0.266352 \\ \hline
   1 & 0 & 1 & 1 & 0.177577 & 0.822423 \\ \hline
   0 & 1 & 1 & 1 & 0.119161 & 0.880839 \\ \hline
   1 & 1 & 1 & 1 & 0.582299 & 0.417701 \\ \hline
\end{tabular}
\end{center}
\caption{Conditional probabilities used in exercise 1}
\end{figure}

\section{Optimizing the executable size}

As the goal was to minimize total package size, we decided to use C to have as small binary size as possible.
On linux linking to the standard library increases binary size quite a lot, so we avoided using it and implemented input and output in Assembly with system calls instead.

%\bibliographystyle{abbrv}\bibliography{ref}

%\appendix

\end{document}
